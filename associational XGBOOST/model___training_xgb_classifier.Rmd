---
title: 'Model Training: XGBOOST Classifier'
author: "Brain K. Masinde"
output:
  pdf_document: default
  html_notebook: default
---

```{r}
# Environment Cleaning: Clearing workspace
rm(list = ls())

# load packages
library(rpart)
library(dplyr)
library(caret)
library(pROC) # For AUC calculation
library(data.table)
library(mlflow)
library(reticulate)
library(Matrix)
library(purrr) # useful for code optimization
library(themis)
library(doMC)
library(here)
```

# Inputs
```{r}
base_train <- read.csv(here("data", "base_train.csv"))
base_validation <- read.csv(here("data", "base_validation.csv"))
base_test <- read.csv(here("data", "base_test.csv"))
```

```{r}
# Combining train and validation datasets to one
# Because we are going to use CV to train the models later
# naming it df_base_train to remain consistent with df naming
df_base_train  <- rbind(base_train, base_validation)

cat("number of rows in combined train data:", nrow(df_base_train), sep = " ")
```


```{r}
# Ensure target variable is a factor
# Ensure the target variable is a factor with valid names
df_base_train$damage_binary_2 <- factor(df_base_train$damage_binary,
                                       levels = c("0", "1"),  # Your current levels
                                       labels = c("Damage_below_10", "Damage_above_10"))  # New valid labels
```

# Model Training using CV
```{r}
# Set up train control with custom seeds
n_folds <- 7
n_models <- 25  # adjust depending on search space size, affects seeds length


# Reproducibility: Defining seeds (a little bit complicated because of parallel processing)

#  Generate a reproducible list of seeds
set.seed(1234)

seeds_list <- vector(mode = "list", length = n_folds + 1)
for (i in 1:n_folds) {
  seeds_list[[i]] <- sample.int(1000000, n_models)  # one seed per model per fold
}
seeds_list[[n_folds + 1]] <- sample.int(1000000, 1)  # for final model



# Set up train control with 10-fold cross-validation
train_control <- trainControl(
  method = "cv",
  number = n_folds, # number of cross-validation folds
  classProbs = TRUE,  # Needed for AUC calculation
  summaryFunction = twoClassSummary,
  sampling = "smote", # caret automatically identifies minority class
  search = "random", # random selection of the expanded grid
  seeds = seeds_list, # Ensures reproducibility
)

# Detect and register the number of available cores (use all but one)
num_cores <- parallel::detectCores() - 2
registerDoMC(cores = num_cores)  # Enable parallel processing


# Measure the time for a code block to run
system.time({
    # Train the model using grid search with 10-fold CV

    xgb_model <- train(damage_binary_2 ~ track_min_dist + 
                       wind_max +
                       rain_total +
                       roof_strong_wall_strong +
                       roof_strong_wall_light +
                       roof_strong_wall_salv +
                       roof_light_wall_strong +
                       roof_light_wall_light +
                       roof_light_wall_salv +
                       roof_salv_wall_strong +
                       roof_salv_wall_light +
                       roof_salv_wall_salv +
                       blue_ss_frac +
                       yellow_ss_frac +
                       orange_ss_frac +
                       red_ss_frac +
                       blue_ls_frac +
                       yellow_ls_frac +
                       orange_ls_frac +
                       red_ls_frac,
        data = df_base_train,
        method = "xgbTree",
        trControl = train_control,
        tuneLength = n_models,  #  this replaces tuneGrid
        metric = "ROC" # "xgbTree" does not support other metrics for classification tasks (e.g., Kappa or F1)
    )
    Sys.sleep(2)  # This is just an example to simulate a delay
})

# Print best parameters
print(xgb_model$bestTune)
```

```{r}
# Extract the best parameters (remove AUC column)
best_params_model <- xgb_model$bestTune

damage_fit_class_full <- train(damage_binary_2 ~ track_min_dist + 
                               wind_max +
                               rain_total +
                               roof_strong_wall_strong +
                               roof_strong_wall_light +
                               roof_strong_wall_salv +
                               roof_light_wall_strong +
                               roof_light_wall_light +
                               roof_light_wall_salv +
                               roof_salv_wall_strong +
                               roof_salv_wall_light +
                               roof_salv_wall_salv +
                               blue_ss_frac +
                               yellow_ss_frac +
                               orange_ss_frac +
                               red_ss_frac +
                               blue_ls_frac +
                               yellow_ls_frac +
                               orange_ls_frac +
                               red_ls_frac, 
          data = df_base_train, # USE TRAINING AND VALIDATION SETS COMBINED
          method = "xgbTree", # XGBoost method
          trControl = trainControl(method = "none"),  # No automatic validation
          tuneGrid = best_params_model # USE BEST PARAMETER
        )
```

```{r}
# Sanity Check
# testing on the training datasets (training + validation)

## Outcome prediction on the final_training_df dataset
## default function predict returns class probabilities (has two columns)
y_pred <- predict(damage_fit_class_full,
                  newdata = df_base_train)


levels(y_pred)


# using table function
conf_matrix <- confusionMatrix(y_pred,
                     df_base_train$damage_binary_2, # remember to use damage_binary_2
                     positive = "Damage_above_10"
                     )
conf_matrix


accuracy <- conf_matrix$overall['Accuracy']

cat("test-set accuracy of associational XGBOOST:", accuracy, sep = " ")
```

# Model - Mlflow
```{r}
# Logging the model and parameter using MLflow

# set tracking URI
mlflow_set_tracking_uri("http://127.0.0.1:5000")

# Ensure any active run is ended
suppressWarnings(try(mlflow_end_run(), silent = TRUE))

# set experiment
# Logging metrics for model training and the parameters used
mlflow_set_experiment(experiment_name = "Attempt 2: R ass-XGBOOST classification - CV (Training metircs)")

# Ensure that MLflow has only one run. Start MLflow run once.
run_name <- paste("XGBoost Run", Sys.time())  # Unique name using current time


# Start MLflow run
mlflow_start_run(nested = FALSE)

# Ensure the run ends even if an error occurs
#on.exit(mlflow_end_run(), add = TRUE)

# Extract the best parameters (remove AUC column)
best_params_model <- xgb_model$bestTune

# Log each of the best parameters in MLflow
for (param in names(best_params_model)) {
  mlflow_log_param(param, best_params_model[[param]])
}

# Log the model type as a parameter
mlflow_log_param("model_type", "ass-xgboost-classification")


# summarize results
conf_matrix <- confusionMatrix(y_pred,
                     df_base_train$damage_binary_2,
                     positive = "Damage_above_10"
                     )

# accuracy
accuracy  <- conf_matrix$overall['Accuracy']

# Positive class = 1, precision, recall, and F1
# Extract precision, recall, and F1 score
precision <- conf_matrix$byClass['Precision']
recall <- conf_matrix$byClass['Recall']
f1_score <- conf_matrix$byClass['F1']


# Log parameters and metrics
# mlflow_log_param("model_type", "scm-xgboost-classification")
mlflow_log_metric("accuracy", accuracy)
mlflow_log_metric("F1", f1_score)
mlflow_log_metric("Precision", precision)
mlflow_log_metric("Recall", recall)


# Save model
#saveRDS(model, file = file.path(path_2_folder, "spam_clas_model.rds"))

# End MLflow run
mlflow_end_run()

```
# Model Testing: Testing on out of sample test data.
```{r}
# Testing on test dataset ----------------------------------------------------------------------------------------
base_test$damage_binary_2 <- factor(base_test$damage_binary,
                                       levels = c("0", "1"),  # Your current levels
                                       labels = c("Damage_below_10", "Damage_above_10"))  # New valid labels

# predict for damage_binary
# Make probability predictions for classification
y_preds_probs <- predict(damage_fit_class_full, 
                         newdata = base_test, type = "prob")[,2]  # Probability of class 1

# AUC
# Compute AUC (better for classification)
auc_value <- auc(roc(base_test$damage_binary_2, y_preds_probs))
auc_value
```

```{r}
## assigning final class based on threshold
threshold = 0.3
y_pred <- ifelse(y_preds_probs > threshold, 1, 0)

y_pred  <- factor(y_pred, levels = c("0", "1"),  # Your current levels
                                       labels = c("Damage_below_10", "Damage_above_10"))  # New valid labels
# using table function
conf_matrix <- confusionMatrix(as.factor(y_pred),
                     base_test$damage_binary_2,
                     positive = "Damage_above_10"
                     )
print(conf_matrix)
```

```{r}
cat("Precision of Positive class: Damage above 10:", conf_matrix$byClass['Precision'], sep = " ")
```

```{r}
cat("Recall of postive class: Damage above 10:", conf_matrix$byClass['Recall'], sep = " ")
```


```{r}
cat("F1 score of positive class: Damage above 10:", conf_matrix$byClass['F1'], sep = " ")
```

# Logging Test metrics - Mlflow 
```{r}
# set tracking URI
mlflow_set_tracking_uri("http://127.0.0.1:5000")

# Ensure any active run is ended
suppressWarnings(try(mlflow_end_run(), silent = TRUE))

# set experiment
# Logging metrics for model training and the parameters used
mlflow_set_experiment(experiment_name = "Attempt 2: R ass- XGBOOST classification - CV (Test metircs)")

# Ensure that MLflow has only one run. Start MLflow run once.
run_name <- paste("XGBoost Run", Sys.time())  # Unique name using current time


# Start MLflow run
mlflow_start_run(nested = FALSE)

# Ensure the run ends even if an error occurs
#on.exit(mlflow_end_run(), add = TRUE)

# Extract the best parameters (remove AUC column)
#best_params_model <- best_params %>% # Remove AUC column if present
#    select(-AUC)

parameters_used  <- xgb_model$bestTune

# Log each of the best parameters in MLflow
for (param in names(parameters_used)) {
  mlflow_log_param(param, parameters_used[[param]])
}

# Log the model type as a parameter
mlflow_log_param("model_type", "ass-xgboost-classification")

# predicting
#   Threshold
threshold = 0.3
y_preds_probs <- predict(damage_fit_class_full, newdata = base_test, type = "prob")[,2]  # Probability of class 1
y_pred <- ifelse(y_preds_probs > threshold, 1, 0)

y_pred  <- factor(y_pred, levels = c("0", "1"),  # Your current levels
                                       labels = c("Damage_below_10", "Damage_above_10"))  # New valid labels

# summarize results
conf_matrix <- confusionMatrix(as.factor(y_pred),
                     base_test$damage_binary_2,
                     positive = "Damage_above_10"
                     )

# accuracy
accuracy  <- conf_matrix$overall['Accuracy']

# Positive class = 1, precision, recall, and F1
# Extract precision, recall, and F1 score
precision <- conf_matrix$byClass['Precision']
recall <- conf_matrix$byClass['Recall']
f1_score <- conf_matrix$byClass['F1']
auc_value <- auc(roc(base_test$damage_binary_2, y_preds_probs))


# Log parameters and metrics
# mlflow_log_param("model_type", "scm-xgboost-classification")
mlflow_log_metric("accuracy", accuracy)
mlflow_log_metric("F1", f1_score)
mlflow_log_metric("Precision", precision)
mlflow_log_metric("Recall", recall)
#mlflow_log_metric("AUC", auc_value)


# Save model
#saveRDS(model, file = file.path(path_2_folder, "spam_clas_model.rds"))

# End MLflow run
mlflow_end_run()
```

# Misc. Experiments
```{r}
# test set confusion matrix
conf_matrix
```

```{r}
# get the false positves by regions (Luzon, Visayas, Mindanao)
# confusion matrix by regions
# Make sure the grouping variable is a factor
# Make sure island_groups is a factor
base_test$island_groups <- as.factor(base_test$island_groups)

# Loop through each group and generate a confusion matrix
for (grp in levels(base_test$island_groups)) {
  
  # Subset data for the current group
  group_indices <- base_test$island_groups == grp
  y_true_group <- base_test$damage_binary_2[group_indices]
  y_pred_group <- y_pred[group_indices]
  
  # Generate and print confusion matrix
  cat("Confusion Matrix for Island Group:", grp, "\n")
  print(confusionMatrix(y_pred_group, y_true_group, positive = "Damage_above_10"))
  cat("\n")
}
```

# Outputs
```{r, eval=FALSE}
saveRDS(damage_fit_class_full, here("associational XGBOOST", "ass_XGBOOST_class.rds"))
```


# OLD CODE
```{r, eval=FALSE, echo=FALSE}
# # setting seed for reproducibility
# set.seed(1234)
# 
# tune_grid <- expand.grid(
#   nrounds = c(47,50, 60,70), # early stopping does not work, we still need to specify nrounds
#   max_depth = c(2, 3, 4, 6),
#   eta = c(0.09, 0.1, 0.11, 0.12),
#   gamma = c(0, 1, 2, 3, 4),
#   colsample_bytree = c(0.9, 1.0, 1.1),
#   min_child_weight = c(2, 3, 4),
#   subsample = c(0.5, 0.6, 0.7, 0.8)
# )
```

